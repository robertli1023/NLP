{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture-03 Gradient Descent and Dymanic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week, we need complete following tasks:\n",
    "+ Re-review the course online programming; \n",
    "+ Choose 1 - 2 books which you interested and keep reading; \n",
    "+ Answer the review questions\n",
    "+ Prepare the basic requirement of our 1st project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I Review the online programming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rm = X[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price(rm, k, b):\n",
    "    return rm * k + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ loss = \\frac{1}{n} \\sum{(y_i - \\hat{y_i})}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ loss = \\frac{1}{n} \\sum{(y_i - (k * x + b)}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial{loss}}{\\partial{k}} = -\\frac{2}{n}\\sum(y_i - (kx_i + b_i))x_i = -\\frac{2}{n}\\sum(y_i - \\hat{y_i})x_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial{loss}}{\\partial{b}} = -\\frac{2}{n}\\sum(y - \\hat{y})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, y_hat):\n",
    "    return sum((y_i - y_hat_i) ** 2 for y_i, y_hat_i in zip(list(y), list(y_hat)))  /len(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_k(x, y, y_hat):\n",
    "    n = len(y)\n",
    "    \n",
    "    gradient = 0\n",
    "    \n",
    "    for x_i, y_i, y_hat_i in zip(list(x), list(y), list(y_hat)):\n",
    "        gradient += (y_i - y_hat_i) * x_i\n",
    "    \n",
    "    return -2 / n * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_b(x, y, y_hat):\n",
    "    n = len(y)\n",
    "    \n",
    "    gradient = 0\n",
    "    \n",
    "    for y_i, y_hat_i in zip(list(y), list(y_hat)):\n",
    "        gradient += (y_i - y_hat_i)\n",
    "    \n",
    "    return -2 / n * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When time is : 0, get best_k: 27.787531574265074 best_b: 36.18835163273809, and the loss is: 35668.754933486714\n",
      "When time is : 50, get best_k: 17.970944431409226 best_b: 34.63696822603767, and the loss is: 15718.600441183406\n",
      "When time is : 100, get best_k: 11.466099977229488 best_b: 33.60620854130385, and the loss is: 6957.557456144256\n",
      "When time is : 150, get best_k: 7.155884803912888 best_b: 32.92045668729494, and the loss is: 3110.170919690716\n",
      "When time is : 200, get best_k: 4.300008954775339 best_b: 32.46333532966365, and the loss is: 1420.59822663818\n",
      "When time is : 250, get best_k: 2.4078962572168603 best_b: 32.15772340689154, and the loss is: 678.6214097574504\n",
      "When time is : 300, get best_k: 1.1544511470624057 best_b: 31.952514248039467, and the loss is: 352.77777758363993\n",
      "When time is : 350, get best_k: 0.3242389339454361 best_b: 31.813840427477338, and the loss is: 209.67747798451455\n",
      "When time is : 400, get best_k: -0.2255048825677327 best_b: 31.719258641847663, and the loss is: 146.8282307808422\n",
      "When time is : 450, get best_k: -0.5893876405476737 best_b: 31.653896137858165, and the loss is: 119.22093467526777\n",
      "When time is : 500, get best_k: -0.8301038361003252 best_b: 31.607897022761595, and the loss is: 107.09001126445285\n",
      "When time is : 550, get best_k: -0.9891999276922685 best_b: 31.574729982541516, and the loss is: 101.75548075835096\n",
      "When time is : 600, get best_k: -1.0942079686646715 best_b: 31.550066838715885, and the loss is: 99.40556251372323\n",
      "When time is : 650, get best_k: -1.1633729307689826 best_b: 31.531039389111168, and the loss is: 98.36632732500975\n",
      "When time is : 700, get best_k: -1.208785412190144 best_b: 31.515746930279267, and the loss is: 97.90267544530039\n",
      "When time is : 750, get best_k: -1.2384576239868366 best_b: 31.502929901904476, and the loss is: 97.69179057118856\n",
      "When time is : 800, get best_k: -1.2576991070967365 best_b: 31.49175361711583, and the loss is: 97.59190913064681\n",
      "When time is : 850, get best_k: -1.2700283940130486 best_b: 31.48166494464968, and the loss is: 97.54077618110259\n",
      "When time is : 900, get best_k: -1.2777771497591999 best_b: 31.472297334825708, and the loss is: 97.51105269707335\n",
      "When time is : 950, get best_k: -1.282490524702494 best_b: 31.463407882054938, and the loss is: 97.49073284740558\n",
      "When time is : 1000, get best_k: -1.2851924608023395 best_b: 31.454835617352487, and the loss is: 97.47454431585582\n",
      "When time is : 1050, get best_k: -1.2865615050501877 best_b: 31.44647386957346, and the loss is: 97.46017178405542\n",
      "When time is : 1100, get best_k: -1.287047317715613 best_b: 31.43825194972611, and the loss is: 97.44659848818732\n",
      "When time is : 1150, get best_k: -1.2869478801605418 best_b: 31.4301230135119, and the loss is: 97.43337791980609\n",
      "When time is : 1200, get best_k: -1.286460658999523 best_b: 31.422056018060182, and the loss is: 97.42031399597916\n",
      "When time is : 1250, get best_k: -1.2857165116224207 best_b: 31.414030391808136, and the loss is: 97.40732060720052\n",
      "When time is : 1300, get best_k: -1.2848021547439314 best_b: 31.406032502330852, and the loss is: 97.39435993838345\n",
      "When time is : 1350, get best_k: -1.2837750538869999 best_b: 31.39805331563911, and the loss is: 97.3814153827545\n",
      "When time is : 1400, get best_k: -1.2826732903622504 best_b: 31.390086845040134, and the loss is: 97.36847964709168\n",
      "When time is : 1450, get best_k: -1.2815220999289165 best_b: 31.382129123226942, and the loss is: 97.35554952818494\n",
      "When time is : 1500, get best_k: -1.2803382058419301 best_b: 31.374177521101448, and the loss is: 97.34262361893707\n",
      "When time is : 1550, get best_k: -1.279132690280401 best_b: 31.36623029637124, and the loss is: 97.3297013010075\n",
      "When time is : 1600, get best_k: -1.277912897189032 best_b: 31.358286294413364, and the loss is: 97.3167823024354\n",
      "When time is : 1650, get best_k: -1.2766836932551902 best_b: 31.350344750042275, and the loss is: 97.30386650337088\n",
      "When time is : 1700, get best_k: -1.2754483035345918 best_b: 31.342405156145254, and the loss is: 97.29095385076418\n",
      "When time is : 1750, get best_k: -1.2742088652046664 best_b: 31.33446717662958, and the loss is: 97.27804432089941\n",
      "When time is : 1800, get best_k: -1.2729667945264485 best_b: 31.326530588734276, and the loss is: 97.26513790294358\n",
      "When time is : 1850, get best_k: -1.2717230300232962 best_b: 31.318595244801163, and the loss is: 97.25223459172051\n",
      "When time is : 1900, get best_k: -1.27047819363083 best_b: 31.31066104694123, and the loss is: 97.23933438453929\n",
      "When time is : 1950, get best_k: -1.2692326974879584 best_b: 31.302727930246647, and the loss is: 97.22643727979896\n"
     ]
    }
   ],
   "source": [
    "trying_times = 2000\n",
    "\n",
    "min_loss = float(\"inf\")\n",
    "\n",
    "current_k = random.random() * 200 - 100\n",
    "current_b = random.random() * 200 - 100\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "update_time = 0\n",
    "\n",
    "best_k = current_k\n",
    "best_b = current_b\n",
    "\n",
    "for i in range(trying_times):\n",
    "    price_k_and_b = [price(x_rm, current_k, current_b) for x_rm in X_rm]\n",
    "    \n",
    "    current_loss = loss(y, price_k_and_b)\n",
    "    \n",
    "    if current_loss < min_loss:\n",
    "        min_loss = current_loss\n",
    "        best_k = current_k\n",
    "        best_b = current_b\n",
    "    \n",
    "    if i % 50 == 0: \n",
    "            print('When time is : {}, get best_k: {} best_b: {}, and the loss is: {}'.format(i, best_k, best_b, min_loss))\n",
    "    \n",
    "    k_gradient = partial_k(X_rm, y, price_k_and_b)\n",
    "    b_gradient = partial_b(X_rm, y, price_k_and_b)\n",
    "    \n",
    "    current_k = current_k + (-1 * k_gradient) * learning_rate\n",
    "    current_b = current_b + (-1 * b_gradient) * learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: change loss function from $loss = \\frac{1}{n}\\sum{(y_i - \\hat(y_i))^2}$ to $loss = \\frac{1}{n}\\sum{|y_i - \\hat{y_i}|}$, and using your mathmatical knowledge to get the right partial formual. Implemen the gradient descent code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_k_and_b(x, y, y_hat):\n",
    "    n = len(y)\n",
    "    \n",
    "    gradient_x = 0\n",
    "    gradient_y = 0\n",
    "    \n",
    "    for x_i, y_i, y_hat_i in zip(list(x), list(y), list(y_hat)):\n",
    "        k = 1\n",
    "        if y_i - y_hat_i < 0: \n",
    "            k = -1\n",
    "        gradient_x +=  k * (-x_i)\n",
    "        gradient_y += k * (-1)\n",
    "    \n",
    "    return gradient_x/n, gradient_y/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When time is : 0, get best_k: 29.222554185832934 best_b: 7.355861153999726, and the loss is: 28627.263771463975\n",
      "When time is : 50, get best_k: 26.080236992157097 best_b: 6.8558611539997365, and the loss is: 22157.106692350968\n",
      "When time is : 100, get best_k: 22.93791979848126 best_b: 6.355861153999747, and the loss is: 16516.6680090922\n",
      "When time is : 150, get best_k: 19.795602604805424 best_b: 5.855861153999758, and the loss is: 11705.94772168774\n",
      "When time is : 200, get best_k: 16.653285411129588 best_b: 5.3558611539997685, and the loss is: 7724.945830137541\n",
      "When time is : 250, get best_k: 13.51096821745368 best_b: 4.855861153999779, and the loss is: 4573.662334441556\n",
      "When time is : 300, get best_k: 10.368651023777755 best_b: 4.35586115399979, and the loss is: 2252.0972345998684\n",
      "When time is : 350, get best_k: 7.2350048577698525 best_b: 3.857521233051171, and the loss is: 763.2405931005094\n",
      "When time is : 400, get best_k: 4.348109798481311 best_b: 3.3935291381895087, and the loss is: 121.76273502221582\n",
      "When time is : 450, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 500, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 550, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 600, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 650, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 700, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 750, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 800, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 850, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 900, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 950, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1000, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1050, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1100, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1150, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1200, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1250, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1300, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1350, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1400, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1450, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1500, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1550, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1600, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1650, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1700, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1750, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1800, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1850, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1900, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n",
      "When time is : 1950, get best_k: 3.1474193439358586 best_b: 3.1826595729721174, and the loss is: 61.25580119276818\n"
     ]
    }
   ],
   "source": [
    "trying_times = 2000\n",
    "\n",
    "min_loss = float(\"inf\")\n",
    "\n",
    "current_k = random.random() * 200 - 100\n",
    "current_b = random.random() * 200 - 100\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "update_time = 0\n",
    "\n",
    "best_k = current_k\n",
    "best_b = current_b\n",
    "\n",
    "for i in range(trying_times):\n",
    "    price_k_and_b = [price(x_rm, current_k, current_b) for x_rm in X_rm]\n",
    "    \n",
    "    current_loss = loss(y, price_k_and_b)\n",
    "    \n",
    "    if current_loss < min_loss:\n",
    "        min_loss = current_loss\n",
    "        best_k = current_k\n",
    "        best_b = current_b\n",
    "    \n",
    "    if i % 50 == 0: \n",
    "            print('When time is : {}, get best_k: {} best_b: {}, and the loss is: {}'.format(i, best_k, best_b, min_loss))\n",
    "    \n",
    "    k_gradient, b_gradient = partial_k_and_b(X_rm, y, price_k_and_b)\n",
    "    \n",
    "    current_k = current_k + (-1 * k_gradient) * learning_rate\n",
    "    current_b = current_b + (-1 * b_gradient) * learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Finish the Solution Parse Part of Edit-Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lru_cache(func):\n",
    "    cache = {}\n",
    "    @wraps(func)\n",
    "    def _wrap(string1, string2): ## ? *args, **kwargs\n",
    "        string = string1 + '-' + string2\n",
    "        if string in cache: result = cache[string]\n",
    "        else:\n",
    "            result = func(string1, string2)\n",
    "            cache[string] = result\n",
    "        return result\n",
    "    return _wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache\n",
    "def edit_distance(string1, string2):\n",
    "    \n",
    "    if len(string1) == 0: return len(string2)\n",
    "    if len(string2) == 0: return len(string1)\n",
    "    \n",
    "    tail_s1 = string1[-1]\n",
    "    tail_s2 = string2[-1]\n",
    "    \n",
    "    candidates = [\n",
    "        (edit_distance(string1[:-1], string2) + 1, 'DEL {}'.format(tail_s1)),  # string 1 delete tail\n",
    "        (edit_distance(string1, string2[:-1]) + 1, 'ADD {}'.format(tail_s2)),  # string 1 add tail of string2\n",
    "    ]\n",
    "    \n",
    "    if tail_s1 == tail_s2:\n",
    "        both_forward = (edit_distance(string1[:-1], string2[:-1]) + 0, '')\n",
    "    else:\n",
    "        both_forward = (edit_distance(string1[:-1], string2[:-1]) + 1, 'SUB {} => {}'.format(tail_s1, tail_s2))\n",
    "\n",
    "    candidates.append(both_forward)\n",
    "    \n",
    "    min_distance, operation = min(candidates, key=lambda x: x[0])\n",
    "    \n",
    "    solution[(string1, string2)] = operation \n",
    "    \n",
    "    return min_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance('ABCDE', 'ABCCEF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('A', 'A'): '',\n",
       " ('A', 'AB'): 'ADD B',\n",
       " ('A', 'ABC'): 'ADD C',\n",
       " ('A', 'ABCC'): 'ADD C',\n",
       " ('A', 'ABCCE'): 'ADD E',\n",
       " ('A', 'ABCCEF'): 'ADD F',\n",
       " ('AB', 'A'): 'DEL B',\n",
       " ('AB', 'AB'): '',\n",
       " ('AB', 'ABC'): 'ADD C',\n",
       " ('AB', 'ABCC'): 'ADD C',\n",
       " ('AB', 'ABCCE'): 'ADD E',\n",
       " ('AB', 'ABCCEF'): 'ADD F',\n",
       " ('ABC', 'A'): 'DEL C',\n",
       " ('ABC', 'AB'): 'DEL C',\n",
       " ('ABC', 'ABC'): '',\n",
       " ('ABC', 'ABCC'): 'ADD C',\n",
       " ('ABC', 'ABCCE'): 'ADD E',\n",
       " ('ABC', 'ABCCEF'): 'ADD F',\n",
       " ('ABCD', 'A'): 'DEL D',\n",
       " ('ABCD', 'AB'): 'DEL D',\n",
       " ('ABCD', 'ABC'): 'DEL D',\n",
       " ('ABCD', 'ABCC'): 'SUB D => C',\n",
       " ('ABCD', 'ABCCE'): 'ADD E',\n",
       " ('ABCD', 'ABCCEF'): 'ADD F',\n",
       " ('ABCDE', 'A'): 'DEL E',\n",
       " ('ABCDE', 'AB'): 'DEL E',\n",
       " ('ABCDE', 'ABC'): 'DEL E',\n",
       " ('ABCDE', 'ABCC'): 'DEL E',\n",
       " ('ABCDE', 'ABCCE'): '',\n",
       " ('ABCDE', 'ABCCEF'): 'ADD F'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance('ATCGGAA', 'ATCGGGA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('A', 'A'): '',\n",
       " ('A', 'AB'): 'ADD B',\n",
       " ('A', 'ABC'): 'ADD C',\n",
       " ('A', 'ABCC'): 'ADD C',\n",
       " ('A', 'ABCCE'): 'ADD E',\n",
       " ('A', 'ABCCEF'): 'ADD F',\n",
       " ('AB', 'A'): 'DEL B',\n",
       " ('AB', 'AB'): '',\n",
       " ('AB', 'ABC'): 'ADD C',\n",
       " ('AB', 'ABCC'): 'ADD C',\n",
       " ('AB', 'ABCCE'): 'ADD E',\n",
       " ('AB', 'ABCCEF'): 'ADD F',\n",
       " ('ABC', 'A'): 'DEL C',\n",
       " ('ABC', 'AB'): 'DEL C',\n",
       " ('ABC', 'ABC'): '',\n",
       " ('ABC', 'ABCC'): 'ADD C',\n",
       " ('ABC', 'ABCCE'): 'ADD E',\n",
       " ('ABC', 'ABCCEF'): 'ADD F',\n",
       " ('ABCD', 'A'): 'DEL D',\n",
       " ('ABCD', 'AB'): 'DEL D',\n",
       " ('ABCD', 'ABC'): 'DEL D',\n",
       " ('ABCD', 'ABCC'): 'SUB D => C',\n",
       " ('ABCD', 'ABCCE'): 'ADD E',\n",
       " ('ABCD', 'ABCCEF'): 'ADD F',\n",
       " ('ABCDE', 'A'): 'DEL E',\n",
       " ('ABCDE', 'AB'): 'DEL E',\n",
       " ('ABCDE', 'ABC'): 'DEL E',\n",
       " ('ABCDE', 'ABCC'): 'DEL E',\n",
       " ('ABCDE', 'ABCCE'): '',\n",
       " ('ABCDE', 'ABCCEF'): 'ADD F',\n",
       " ('A', 'AT'): 'ADD T',\n",
       " ('A', 'ATC'): 'ADD C',\n",
       " ('A', 'ATCG'): 'ADD G',\n",
       " ('A', 'ATCGG'): 'ADD G',\n",
       " ('A', 'ATCGGG'): 'ADD G',\n",
       " ('A', 'ATCGGGA'): 'ADD A',\n",
       " ('AT', 'A'): 'DEL T',\n",
       " ('AT', 'AT'): '',\n",
       " ('AT', 'ATC'): 'ADD C',\n",
       " ('AT', 'ATCG'): 'ADD G',\n",
       " ('AT', 'ATCGG'): 'ADD G',\n",
       " ('AT', 'ATCGGG'): 'ADD G',\n",
       " ('AT', 'ATCGGGA'): 'ADD A',\n",
       " ('ATC', 'A'): 'DEL C',\n",
       " ('ATC', 'AT'): 'DEL C',\n",
       " ('ATC', 'ATC'): '',\n",
       " ('ATC', 'ATCG'): 'ADD G',\n",
       " ('ATC', 'ATCGG'): 'ADD G',\n",
       " ('ATC', 'ATCGGG'): 'ADD G',\n",
       " ('ATC', 'ATCGGGA'): 'ADD A',\n",
       " ('ATCG', 'A'): 'DEL G',\n",
       " ('ATCG', 'AT'): 'DEL G',\n",
       " ('ATCG', 'ATC'): 'DEL G',\n",
       " ('ATCG', 'ATCG'): '',\n",
       " ('ATCG', 'ATCGG'): 'ADD G',\n",
       " ('ATCG', 'ATCGGG'): 'ADD G',\n",
       " ('ATCG', 'ATCGGGA'): 'ADD A',\n",
       " ('ATCGG', 'A'): 'DEL G',\n",
       " ('ATCGG', 'AT'): 'DEL G',\n",
       " ('ATCGG', 'ATC'): 'DEL G',\n",
       " ('ATCGG', 'ATCG'): 'DEL G',\n",
       " ('ATCGG', 'ATCGG'): '',\n",
       " ('ATCGG', 'ATCGGG'): 'ADD G',\n",
       " ('ATCGG', 'ATCGGGA'): 'ADD A',\n",
       " ('ATCGGA', 'A'): 'DEL A',\n",
       " ('ATCGGA', 'AT'): 'DEL A',\n",
       " ('ATCGGA', 'ATC'): 'DEL A',\n",
       " ('ATCGGA', 'ATCG'): 'DEL A',\n",
       " ('ATCGGA', 'ATCGG'): 'DEL A',\n",
       " ('ATCGGA', 'ATCGGG'): 'SUB A => G',\n",
       " ('ATCGGA', 'ATCGGGA'): '',\n",
       " ('ATCGGAA', 'A'): 'DEL A',\n",
       " ('ATCGGAA', 'AT'): 'DEL A',\n",
       " ('ATCGGAA', 'ATC'): 'DEL A',\n",
       " ('ATCGGAA', 'ATCG'): 'DEL A',\n",
       " ('ATCGGAA', 'ATCGG'): 'DEL A',\n",
       " ('ATCGGAA', 'ATCGGG'): 'DEL A',\n",
       " ('ATCGGAA', 'ATCGGGA'): ''}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 Choose 1 - 2 books to keep reading: \n",
    "\n",
    "+ SICP, Structure and Interpretation of Computer Programming. \n",
    "+ Introduction to Algorithms \n",
    "+ Artificial Intelligence A Modern Approach (3rd Edition) \n",
    "+ Code Complete 2 \n",
    "+ Programming Pearls \n",
    "+ Deep Learning\n",
    "+ 黑客与画家\n",
    "+ 数学之美\n",
    "+ Fluent Python\n",
    "+ Hands on Tensorflow\n",
    "+ Conference: NIPS_ ICML_ ICLR_ ACL_ AAAI\n",
    "\n",
    "> most books you may find in our github: https://github.com/Computing-Intelligence/References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5-1: review machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Why do we use Derivative / Gredient to fit a target function?¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:the Derivative/Gredient value indicates the change rule of a funtion, we can use that to keep adjust the function and keep approching to a extremum value of the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In the words 'Gredient Descent', what's the Gredient and what's the Descent?¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  for a function,gradient is a vector when the function changes fastest along this direction (the direction of the gradient) at this point,for example:\n",
    "$$f(x, y)$$\n",
    "the gradient is:\n",
    "$$(\\frac{\\partial{f}}{\\partial{x}}, \\frac{\\partial{f}}{\\partial{y}})$$\n",
    "when we descend in the direction of the gradient, it calles gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. What's the advantages of the 3rd gradient descent method compared to the previous methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: in each iteration ,we caculate the result and get the fastest descend direction, and adjust function parameters to that direction, this helps us to get a good result always towards the right direction and much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Using the simple words to describe: What's the machine leanring.¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: machine learning is that the machine could calculte the result of each step, and adjust itself to get better result in the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Answer following questions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Why do we need dynamic programming? What's the difference of dynamic programming and previous talked `search` problme? \n",
    "\n",
    "Dynamic programming transformed the multi-stage process is into a series of single-stage problems, which are solved one by one by making use of the relationship between the stages.\n",
    "\n",
    "The difference is that the dynamic only compute the same process once, and the newer calculating process could take advantages of the older process result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Why do we still need dynamic programming? Why not we train a machine learning to fit a function which could get the `right` answer based on inputs?\n",
    "\n",
    "Choose Dynamic Programming when you explicitly know the model, and get the right answer step by step, at the last step, the answer should be the exactly right answer, not approximate answer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Can you catch up at least 3 problems which could solved by Dynamic Programming? \n",
    "\n",
    "Package delivery; shortest road in a map; knapsack problem;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Can you catch up at least 3 problems wich could sloved by Edit Distance? \n",
    "\n",
    "spelling check;\n",
    "paper pass;\n",
    "gene sequence analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Please summarize the three main features of Dynamic Programming, and make a concise explain for each feature. \n",
    "\n",
    "\n",
    "1. best result: the model should have the best result\n",
    "2. decomposable: could decomposate the multi-stage process is into a series of single-stage problems\n",
    "3. storage the result: storge the result of each step for later usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What's the disadvantages of Dynamic Programming? (You may need search by yourself in Internet)\n",
    "\n",
    "\n",
    "1. cost memeory space;\n",
    "2. takes time to figure out how to decomposate the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 Preparation of Project-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using python Flask or Bottle to finish your first simple web app:\n",
    "> https://bottlepy.org/\n",
    "\n",
    "2. Learn what's the SQL, and try some simple SQL operations:\n",
    "> https://www.w3schools.com/sql/sql_intro.asp\n",
    "\n",
    "3. Learn what's the HTML ( *ONLY* need to know the basic things)\n",
    "> https://getbootstrap.com/; https://www.w3schools.com/html/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting bottle\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/69/d1/efdd0a5584169cdf791d726264089ce5d96846a8978c44ac6e13ae234327/bottle-0.12.17-py3-none-any.whl (89kB)\n",
      "Installing collected packages: bottle\n",
      "Successfully installed bottle-0.12.17\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bottle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Jul/2019 12:45:49] \"GET /hello/world HTTP/1.1\" 200 19\n",
      "127.0.0.1 - - [16/Jul/2019 12:45:53] \"GET /hello/lucy HTTP/1.1\" 200 18\n"
     ]
    }
   ],
   "source": [
    "from bottle import route, run, template\n",
    "\n",
    "@route('/hello/<name>')\n",
    "def index(name):\n",
    "    return template('<b>Hello {{name}}</b>!', name = name)\n",
    "\n",
    "run(host='localhost', port = 8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optinal) Finish the k-person-salesman problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitudes = [random.randint(-100, 100) for _ in range(20)]\n",
    "longitude = [random.randint(-100, 100) for _ in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(latitudes, longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定一个初始点 𝑃, 已经 𝑘个车辆，如何从该点出发，经这 k 个车辆经过所以的点全部一次，而且所走过的路程最短?\n",
    "\n",
    "例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_p = (-50, 10)\n",
    "chosen_p2 = (1, 30)\n",
    "chosen_p3 = (99, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x11dbbd470>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(latitudes, longitude)\n",
    "plt.scatter([chosen_p[0]], [chosen_p[1]], color='r')\n",
    "plt.scatter([chosen_p2[0]], [chosen_p2[1]], color='r')\n",
    "plt.scatter([chosen_p3[0]], [chosen_p3[1]], color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
